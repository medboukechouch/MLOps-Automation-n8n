# Guide d'utilisation

## ğŸš€ Utilisation rapide

### 1. Scraper les propriÃ©tÃ©s

```bash
python scripts/scrape.py
```

Cela va:
1. Visiter le site Mubawab.ma
2. Extraire les donnÃ©es des propriÃ©tÃ©s
3. Envoyer les donnÃ©es Ã  Google Sheets

### 2. GÃ©nÃ©rer les prÃ©dictions

```bash
python scripts/predict.py
```

Cela va:
1. Lire les donnÃ©es de Google Sheets
2. PrÃ©traiter les donnÃ©es
3. GÃ©nÃ©rer les prÃ©dictions avec 4 modÃ¨les
4. Ã‰crire les rÃ©sultats dans un nouvel onglet "Predictions"

## ğŸ“Š Utilisation en Python

### Import basique

```python
from src.scraper import PropertyScraper
from src.preprocessor import DataPreprocessor
from src.models import PricePredictor

# Scraper
scraper = PropertyScraper()
df = scraper.scrape()

# PrÃ©traiter
preprocessor = DataPreprocessor()
df_clean = preprocessor.preprocess(df)

# PrÃ©dire
predictor = PricePredictor()
predictions = predictor.predict(df_clean)
```

### Avec Google Sheets

```python
from src.sheets_handler import SheetsHandler

# Lire
handler = SheetsHandler()
df = handler.read_input("Feuille 1")

# Ã‰crire
handler.write_output(df, worksheet_name="Resultats")
```

## ğŸ”§ Configuration avancÃ©e

### Modifier les paramÃ¨tres de scraping

Ã‰diter `configs/config.py`:

```python
BASE_URL = "https://www.mubawab.ma/fr/sc/villas-a-vendre"  # Changer le type de bien
MAX_ADS = 5000  # Limiter le nombre d'annonces
```

### Utiliser des modÃ¨les personnalisÃ©s

```python
from src.models import PricePredictor

predictor = PricePredictor()

# PrÃ©dictions individuelles
predictions = predictor.predict(X_new)

# Moyenne pondÃ©rÃ©e
weights = {
    "Linear_Regression": 0.1,
    "Random_Forest": 0.4,
    "Gradient_Boosting": 0.4,
    "SVR": 0.1
}
ensemble_pred = predictor.predict_ensemble(X_new, weights=weights)

# Avec intervalle de confiance
result = predictor.predict_with_confidence(X_new)
print(f"PrÃ©diction: {result['predictions'][0]}")
print(f"Intervalle: [{result['lower_bound'][0]}, {result['upper_bound'][0]}]")
```

## ğŸ”„ Automatisation avec n8n

### Configuration simple

1. Installer n8n (ou utiliser cloud.n8n.io)
2. CrÃ©er un nouveau workflow
3. Ajouter un trigger "Cron" (pour l'horaire)
4. Ajouter une action "Execute Command"
5. Configurer le script:
   ```bash
   python C:\path\to\scripts\scrape.py
   ```

### Configuration complÃ¨te (Scraping + PrÃ©dictions)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cron Trigger   â”‚ (Chaque jour Ã  18h)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute: scrape.py  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Google Sheets Webhook   â”‚ (Optionnel)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute: predict.py â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ˆ Suivi des performances

### Ã‰valuer les modÃ¨les

```python
from src.models import ModelEvaluator
import pandas as pd

# Charger les donnÃ©es de test
y_true = pd.read_csv("data/test_prices.csv")['prix']
predictions = {
    'Linear_Regression': [...],
    'Random_Forest': [...],
    'Gradient_Boosting': [...],
    'SVR': [...]
}

# Comparer
results = ModelEvaluator.compare_models(y_true, predictions)
print(results)
```

## ğŸ› DÃ©pannage

### Les donnÃ©es ne s'envoient pas Ã  Google Sheets

```bash
# VÃ©rifier la connexion
python -c "from src.sheets_handler import SheetsHandler; SheetsHandler()"
```

### Le scraping est trop lent

```python
# RÃ©duire le nombre d'annonces
from src.scraper import PropertyScraper
scraper = PropertyScraper(max_ads=100)  # Au lieu de 100000
```

### Les prÃ©dictions sont nulles

```python
# VÃ©rifier les donnÃ©es prÃ©parÃ©es
print(X_prepared.head())
print(X_prepared.dtypes)
print(X_prepared.isnull().sum())
```

## ğŸ“š Exemples complets

### Exemple 1: Pipeline complet

```python
import pandas as pd
from src.scraper import PropertyScraper
from src.preprocessor import DataPreprocessor
from src.models import PricePredictor
from src.sheets_handler import SheetsHandler, prepare_output

# 1. Scraper
scraper = PropertyScraper(max_ads=1000)
df = scraper.scrape()

# 2. PrÃ©traiter
preprocessor = DataPreprocessor()
df_clean = preprocessor.preprocess(df)
df_prepared, prix_reel = preprocessor.encode_and_scale(df_clean, fit=False)

# 3. PrÃ©dire
predictor = PricePredictor()
predictions = predictor.predict(df_prepared)

# 4. Sauvegarder
output_df = prepare_output(df_clean, predictions, prix_reel)
handler = SheetsHandler()
handler.write_output(output_df)
```

### Exemple 2: Analyse statistique

```python
from src.models import ModelEvaluator
import matplotlib.pyplot as plt

# Comparer les modÃ¨les
results = ModelEvaluator.compare_models(y_true, predictions)

# Visualiser
results.plot(kind='bar')
plt.ylabel('Score')
plt.title('Comparaison des modÃ¨les')
plt.show()
```

## ğŸ†˜ Support

Pour toute question:
- VÃ©rifier les logs dans le terminal
- Ouvrir une issue sur GitHub
- Consulter la [FAQ](FAQ.md)
