# Property Price Predictor ğŸ 

Un systÃ¨me complet de scraping et prÃ©diction des prix immobiliers au Maroc, intÃ©grÃ© avec n8n pour l'automatisation.

## ğŸ“‹ Vue d'ensemble

Ce projet combine:
- **Web Scraping** : Collecte automatisÃ©e de donnÃ©es immobiliÃ¨res depuis Mubawab.ma
- **PrÃ©traitement** : Nettoyage et enrichissement des donnÃ©es
- **Machine Learning** : PrÃ©diction des prix avec 4 modÃ¨les (Linear Regression, Random Forest, Gradient Boosting, SVR)
- **Automatisation** : IntÃ©gration n8n pour le pipeline continu
- **Google Sheets** : Stockage et affichage des rÃ©sultats en temps rÃ©el

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis

- Python 3.8+
- Chrome/Chromium
- Compte Google Cloud (pour Google Sheets API)
- (Optionnel) n8n pour l'automatisation

### Installation

```bash
# Cloner le projet
git clone https://github.com/medboukechouch/MLOps-Automation-n8n.git
cd MLOps-Automation-n8n

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Configuration

1. **Service Account Google** : Placer `service_account.json` dans le dossier `configs/`
2. **ChromeDriver** : TÃ©lÃ©charger et configurer le chemin dans `configs/config.py`
3. **Variables d'environnement** : CrÃ©er un fichier `.env` :

```env
# Google Sheets
SHEET_NAME=Scraped Properties
WORKSHEET_NAME=Feuille 1

# n8n (optionnel)
WEBHOOK_URL=http://localhost:5678/webhook/your-webhook-id
MODEL_DIR=./models

# Scraping
CHROMEDRIVER_PATH=C:/webdrivers/chromedriver.exe
BASE_URL=https://www.mubawab.ma/fr/sc/appartements-a-vendre
MAX_ADS=100000

# Service Account
SERVICE_ACCOUNT_PATH=configs/service_account.json
```

## ğŸ“ Structure du projet

```
property-price-predictor/
â”œâ”€â”€ src/                          # Code source principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scraper.py               # Web scraping
â”‚   â”œâ”€â”€ preprocessor.py          # PrÃ©traitement des donnÃ©es
â”‚   â”œâ”€â”€ models.py                # Chargement et prÃ©dictions ML
â”‚   â”œâ”€â”€ sheets_handler.py        # IntÃ©gration Google Sheets
â”‚   â””â”€â”€ utils.py                 # Fonctions utilitaires
â”‚
â”œâ”€â”€ models/                       # ModÃ¨les ML prÃ©-entraÃ®nÃ©s
â”‚   â”œâ”€â”€ modele_Linear_Regression.pkl
â”‚   â”œâ”€â”€ modele_Random_Forest.pkl
â”‚   â”œâ”€â”€ modele_Gradient_Boosting.pkl
â”‚   â”œâ”€â”€ modele_SVR.pkl
â”‚   â”œâ”€â”€ encoder.pkl              # One-hot encoder
â”‚   â”œâ”€â”€ scaler.pkl               # StandardScaler
â”‚   â””â”€â”€ features_columns.pkl     # Colonnes features
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # DonnÃ©es brutes
â”‚   â””â”€â”€ processed/               # DonnÃ©es nettoyÃ©es
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_exploration.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â””â”€â”€ 03_model_training.ipynb
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.py                # Configuration centralisÃ©e
â”‚   â”œâ”€â”€ service_account.json     # (Ã€ ne pas committer)
â”‚   â””â”€â”€ n8n_workflow.json        # Configuration n8n
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ INSTALLATION.md
â”‚   â”œâ”€â”€ USAGE.md
â”‚   â””â”€â”€ API.md
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scrape.py               # Script de scraping standalone
â”‚   â”œâ”€â”€ predict.py              # Script de prÃ©diction standalone
â”‚   â””â”€â”€ train_models.py         # Script d'entraÃ®nement
â”‚
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ .gitignore                   # Fichiers Ã  ignorer
â”œâ”€â”€ .env.example                 # Exemple de configuration
â””â”€â”€ LICENSE                      # Licence du projet
```

## ğŸ”„ Flux de travail

### 1. Scraping des donnÃ©es
```bash
python scripts/scrape.py
```

Collecte les donnÃ©es immobiliÃ¨res et les envoie Ã  Google Sheets.

### 2. PrÃ©diction des prix
```bash
python scripts/predict.py
```

Charge les donnÃ©es de Google Sheets, applique le prÃ©traitement et gÃ©nÃ¨re les prÃ©dictions.

### 3. Automatisation avec n8n
Configure un workflow n8n qui:
1. DÃ©clenche le scraping Ã  intervalle rÃ©gulier
2. Envoie les donnÃ©es Ã  Google Sheets via webhook
3. Lance automatiquement les prÃ©dictions

## ğŸ“Š ModÃ¨les disponibles

Le projet inclut 4 modÃ¨les de prÃ©diction:

| ModÃ¨le | MAE | RMSE | RÂ² |
|--------|-----|------|-----|
| Linear Regression | 0.31 | 0.45 | 0.80 |
| Random Forest | 0.31 | 0.47 | 0.78 |
| Gradient Boosting | 0.31 | 0.51 | 0.74 |
| XGBoost | 0.31 | 0.44 | 0.81 |

## ğŸ”‘ FonctionnalitÃ©s principales

### Scraping
- âœ… Extraction complÃ¨te des annonces (prix, surface, piÃ¨ces, etc.)
- âœ… DÃ©tection des extras (ascenseur, climatisation, etc.)
- âœ… Gestion des utilisateurs-agents
- âœ… Envoi via webhook n8n
- âœ… Stockage dans Google Sheets

### PrÃ©traitement
- âœ… Nettoyage des valeurs manquantes
- âœ… Conversion des unitÃ©s (EUR â†’ DH)
- âœ… Extraction des zones et villes
- âœ… Encodage one-hot des variables catÃ©gorielles
- âœ… Standardisation des variables numÃ©riques

### PrÃ©diction
- âœ… PrÃ©dictions avec 4 modÃ¨les
- âœ… Comparaison automatique
- âœ… Export des rÃ©sultats dans Google Sheets
- âœ… Support des variables manquantes

## ğŸ› ï¸ Technologies utilisÃ©es

- **Scraping** : Selenium, BeautifulSoup
- **DonnÃ©es** : Pandas, NumPy
- **ML** : Scikit-learn, Joblib
- **Google** : gspread, google-auth
- **Automatisation** : n8n
- **Dev** : Python 3.8+, Git

## ğŸ“ Exemples d'utilisation

### Utilisation basique
```python
from src.scraper import PropertyScraper
from src.preprocessor import DataPreprocessor
from src.models import PricePredictor

# Scraper
scraper = PropertyScraper()
data = scraper.scrape_properties()

# PrÃ©traiter
preprocessor = DataPreprocessor()
clean_data = preprocessor.preprocess(data)

# PrÃ©dire
predictor = PricePredictor()
predictions = predictor.predict(clean_data)
```

### Avec Google Sheets
```python
from src.sheets_handler import SheetsHandler

sheets = SheetsHandler()
raw_data = sheets.read_input()
predictions = predict(raw_data)
sheets.write_output(predictions)
```

## ğŸ” SÃ©curitÃ©

âš ï¸ **Important** : 
- Ne jamais committer `service_account.json`
- Ne pas exposer les webhooks n8n
- Utiliser des variables d'environnement pour les clÃ©s sensibles
- Voir `.gitignore` pour les fichiers ignorÃ©s

## ğŸ“š Documentation complÃ¨te

- [Installation dÃ©taillÃ©e](docs/INSTALLATION.md)
- [Guide d'utilisation](docs/USAGE.md)
- [RÃ©fÃ©rence API](docs/API.md)
- [Configuration n8n](docs/N8N_SETUP.md)

## ğŸ¤ Contribution

Les contributions sont bienvenues! Veuillez:
1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/amazing-feature`)
3. Committer vos changements (`git commit -m 'Add amazing feature'`)
4. Pusher vers la branche (`git push origin feature/amazing-feature`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ‘¨â€ğŸ’¼ Auteur

DÃ©veloppÃ© par **Mohamed BOUKECHOUCH** et **Mohammed KARRAJI** comme projet fin d'Ã©tudes (PFE)

## ğŸ’¬ Support

Pour toute question ou problÃ¨me:
- Ouvrir une [issue](https://github.com/medboukechouch/MLOps-Automation-n8n/issues)
- Contacter directement

## ğŸ¯ Roadmap

- [ ] API REST avec FastAPI
- [ ] Interface web (Streamlit/Django)
- [ ] Support de plusieurs sites immobiliers
- [ ] ModÃ¨les d'apprentissage profond (Deep Learning)
- [ ] Dashboard en temps rÃ©el
- [ ] Tests unitaires complets

---

**DerniÃ¨re mise Ã  jour** : Janvier 2026
